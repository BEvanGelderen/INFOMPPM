{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jru9llEE_Hin"
   },
   "source": [
    "# ðŸ‘‹ Welcome to the first INFOMPPM seminar ðŸ‘‹\n",
    "\n",
    "During the seminar session, we'll begin by exploring how public values are intertwined with recommender systems. You'll need to consider the type of data required to develop a recommender system, along with the potential opportunities and risks these systems pose to different values. Next, we will delve into the basics of creating a recommender system in Python, covering:\n",
    "\n",
    "1. Non-personalized recommendations (including ratings, seeding, confidence, and support)\n",
    "2. Implicit ratings\n",
    "3. Using Streamlit\n",
    "\n",
    "The activities are designed to test your understanding of the readings, help you get your codebook operational, extract features from existing data, and engage with core concepts.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "The dataset you for this assignment will be the [Book-Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/) mined by [Cai-Nicolas Ziegler](http://dbis.informatik.uni-freiburg.de/team/ziegler/cai).\n",
    "\n",
    "The dataset:\n",
    "> ... a 4-week crawl (August / September 2004) from the Book-Crossing community with kind permission from Ron Hornbaker, CTO of Humankind Systems. Contains 278,858 users (anonymized but with demographic information) providing 1,149,780 ratings (explicit / implicit) about 271,379 books.\n",
    "\n",
    "Although the dataset may seem outdated, it serves as an excellent starting point and presents several challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLCEQhwM_LSx"
   },
   "source": [
    "# ðŸ”¬ Data exploration and preparation\n",
    "In this notebook, we'll examine the dataset and create a subset of it for further analysis. The dataset was relatively clean when downloaded, though we addressed some problematic delimiter issues for you. If you're interested in tackling these issues firsthand, the original dataset is available at the [Book-Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jbid18cs_LS3"
   },
   "source": [
    "### 1. Loading the data\n",
    "Load the three datasets and explore the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "LfURRUv5_LS7",
    "ExecuteTime": {
     "end_time": "2024-02-19T15:28:17.246183Z",
     "start_time": "2024-02-19T15:28:14.098785500Z"
    }
   },
   "outputs": [],
   "source": [
    "# code goes here\n",
    "import pandas as pd\n",
    "df_books_ratings = pd.read_csv('data/BX-Book-Ratings.csv', sep=';', encoding='latin-1')\n",
    "df_books = pd.read_csv('data/BX-Books.csv', low_memory=False, sep=';', encoding='latin-1')\n",
    "df_users = pd.read_csv('data/BX-Users.csv', low_memory=False, sep=';', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwtaLulV_LS-"
   },
   "source": [
    "### 2. Cleaning the data\n",
    "Ensure that all reviews are linked to a book. Investigate whether there are any reviews that lack a corresponding book or user. Verify the accuracy of author names and identify any anomalies, such as users who have submitted an unusually high number of reviews. Describe the process you followed to clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LIVYD1kJ_LTA",
    "ExecuteTime": {
     "end_time": "2024-02-19T15:25:59.399313500Z",
     "start_time": "2024-02-19T15:25:59.165012100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "dtype: int64\n",
      "\n",
      "Books\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n",
      "\n",
      "Users\n",
      "User-ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# code goes here\n",
    "# check for missing values\n",
    "print(\"\\nRatings\")\n",
    "print(df_books_ratings.isnull().sum())\n",
    "print(\"\\nBooks\")\n",
    "print(df_books.isnull().sum())\n",
    "print(\"\\nUsers\")\n",
    "print(df_users.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Age is often missing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User-ID        ISBN  Book-Rating\n",
      "0   276725  034545104X            0\n",
      "1   276726  0155061224            5\n",
      "2   276727  0446520802            0\n",
      "3   276729  052165615X            3\n",
      "4   276729  0521795028            6\n",
      "(1149779, 3)\n",
      "(118604, 3)\n",
      "    User-ID        ISBN  Book-Rating\n",
      "6    276736  3257224281            8\n",
      "7    276737  0600570967            6\n",
      "9    276745   342310538           10\n",
      "25   276748  3442437407            0\n",
      "26   276751  033390804X            0\n"
     ]
    }
   ],
   "source": [
    "#list all the reviews that are not linked to a book\n",
    "rating_with_no_existing_book = df_books_ratings[df_books_ratings['ISBN'].isin(df_books['ISBN']) == False]\n",
    "print(df_books_ratings.head())\n",
    "print(df_books_ratings.shape)\n",
    "print(rating_with_no_existing_book.shape)\n",
    "print(rating_with_no_existing_book.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T15:33:18.220476200Z",
     "start_time": "2024-02-19T15:33:17.906969300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "About 10 percent of ratings refer to a non-existing ISBN in the book.csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eG98wDxB_LTC"
   },
   "source": [
    "### 3. Subsetting the data\n",
    "The publication accompanied with this dataset [Improving Recommendation Lists Through Topic Diversification](http://www2.informatik.uni-freiburg.de/~cziegler/BX/WWW-2005-Preprint.pdf) by Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, Georg Lausen; describes the process of subsetting (condensation steps) the dataset as follows (p5):\n",
    "\n",
    "> Hence, we discarded all books missing taxonomic descriptions, along with all ratings referring to them. Next, we also removed book titles with fewer than 20 overall mentions. Only community members with at least five ratings each were kept.\n",
    "\n",
    "Investigate the significance of these parameters for the dataset as a whole. Additionally, decide whether to include implicit ratings (where Book-Rating equals 0) in your final dataset. Consider the potential consequences of this choice. Would you opt to exclude them prior to assessing other parameters, or would it be more appropriate to exclude them later?\n",
    "\n",
    "Although the publication outlines the expected dimensions of the resulting dataset, it's acceptable if your findings vary at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaFTwcHs_LTE"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWdzViW__LTH"
   },
   "source": [
    "### 4. Extra step\n",
    "Examine the `BX-Books.csv` file specifically for the book Robots and _Empire by Isaac Asimov_. Identify any issues you come across. Would you address these issues?\n",
    "\n",
    "Given that this could pose a problem for our dataset, consider how you would resolve it. You may need to revisit step 2 if you decide to undertake this additional step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKxggT9T_LTJ"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJWyrqxs_LTK"
   },
   "source": [
    "### 5. Save the new dataset(s)\n",
    "Save the dataset(s) in distinct named CSV-files for later usage. Move the file(s) to the data directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEsSD26E_LTL"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8kFbkji_Rvm"
   },
   "source": [
    "# ðŸ“š Recommendations based on most reviewed books\n",
    "You will start by generating recommendations based on the most reviewed books. Although this approach is not personalized, it remains widely used and provides an opportunity to familiarize yourself with the Streamlit app located in the app directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTuGZoV1_Rvt"
   },
   "source": [
    "### 1. Calculate the total reviews per book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovFJr463_Rvv"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BoVIGGW_Rvx"
   },
   "source": [
    "### 2. Save the recommendations\n",
    "\n",
    "Select the top 10 books based on the number of reviews. Save these recommendations in a file named `recommendations-most-reviewed.csv`. Then, update the `app/recommendations` directory by replacing the existing recommendations file with this new one. The current recommendations in the app require significant improvements. Ensure the file includes the following columns: `ISBN;count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhRLTR2P_Rvy"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyOUHwcf_Rvz"
   },
   "source": [
    "### 3. Run the Streamlit app\n",
    "This might be your first experience running a Streamlit app. We've supplied you with boilerplate code to view your recommendations through a functional interface. As you progress, you may want to adjust some buttons or include additional metadata. Therefore, it's beneficial to familiarize yourself with the [Streamlit documentation](https://docs.streamlit.io/library/api-reference). For aspiring data scientists, the ability to create quick proofs-of-concept is essential.\n",
    "\n",
    "1. Install Streamlit\n",
    "2. Go to the terminal, navigate to the `app` folder and type `streamlit run app.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDCY9T1A_Yza"
   },
   "source": [
    "# ðŸ“š Recommendations based on average ratings\n",
    "You will create your first recommendations using average ratings. This method highlights books with high reader ratings, combining popularity with quality. You'll calculate each book's average rating and choose the top-rated ones for your recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynjIkPDW_Yzi"
   },
   "source": [
    "### 1. Calculate the average ratings\n",
    "Calculate the average ratings and the number of reviews (count) for the books in your new dataset(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNBwsvZ6_Yzl"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_zPPohE_Yzn"
   },
   "source": [
    "### 2. Save the recommendations\n",
    "Choose the top 10 based on ratings and save them as `recommendations-ratings-avg.csv`, replacing the existing file in the app directory. Ensure the file includes the columns: `ISBN;mean`. After you have saved it you can refresh Streamlit to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJtsMXUq_Yzn"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feklVK4C_Yzo"
   },
   "source": [
    "### 3. Reflect on the recommendations\n",
    "Examine the average rating and number of reviews for the top 10 books. Reflect on why solely using average ratings isn't the best method for recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6dG12VM_dv7"
   },
   "source": [
    "# ðŸ“š Recommendations based on weighted ratings\n",
    "Considering the drawbacks of using average ratings, you will now develop recommendations based on the weighted average for each book. Refer to the article [Building a Recommendation System using weighted-average score](https://medium.com/@developeraritro/building-a-recommendation-system-using-weighted-hybrid-technique-75598b6be8ed) to understand and apply this concept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbKQzg9L_dwC"
   },
   "source": [
    "### 1. Calculate Weightage Average for Individual books average rating\n",
    "Determine the mean vote value (C) for the entire dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLAfkwqh_dwE"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBjbZi7I_dwG"
   },
   "source": [
    "### 2. Save the recommendations\n",
    "Choose the top 10 books based on their weighted ratings and save these recommendations as `recommendations-ratings-weight.csv`. Then, update the app directory by replacing the existing file. Ensure the file includes the columns: `ISBN;weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekGW42KY_dwH"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHRCP9HM_dwI"
   },
   "source": [
    "### 3. Compare recommendations based on average rating and weighted ratings\n",
    "Review the interface to note any significant differences with this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMVdK05N_iQJ"
   },
   "source": [
    "# ðŸ“š Recommendations based on Frequently Reviewed Together (frequency)\n",
    "Use the `permutations` function from `itertools` to create combinations of books that are frequently reviewed together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fn8as5VL_iQZ"
   },
   "source": [
    "### 1. Quick introduction to permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GRn2hCV_iQc"
   },
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "# items bought together\n",
    "items = ['milk', 'bread', 'eggs']\n",
    "\n",
    "# this code creates sets of 2 items from the itemset above\n",
    "list(permutations(items, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ln0XQocY_iQg"
   },
   "source": [
    "### 2. Count the combinations of books reviewed together\n",
    "Create combinations with `permutations` and count how often each combination occurs. This process might be time-consuming, depending on your initial data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CC_V03SI_iQm"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95nyhhT8_iQn"
   },
   "source": [
    "### 3. Save the recommendations\n",
    "Given the potential size of the output, limit the CSV file to include only the top 10 recommendations per book. Save this as `recommendations-seeded-freq.csv` and update the file in the app directory. Remember to enable the code block related to this step if it was previously commented out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bebM1kk8_mbZ"
   },
   "source": [
    "# ðŸ“š Recommendations based on Frequently Reviewed Together (association rules)\n",
    "For the final segment of this assignment, refer to section 5.4 of the _Practical Recommender Systems_ book (pages 113-127). After reading, download the code provided by the book and focus on the `association_rules_calculator.py` in the `builder` directory. Your task is to adapt this code for use in this notebook, translating its steps into a format suitable for our environment. Here's a simplified outline based on the source code:\n",
    "\n",
    "The steps found in the source code are:\n",
    "1. Load the data\n",
    "2. Generate transactions or, in our case reviews\n",
    "3. Calculate the Support Confidence\n",
    "4. Save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxi68WnH_mbi"
   },
   "source": [
    "### 1. Load the data\n",
    "Instead of using a database, load your `.csv` files into a dataframe. Select the data necessary for identifying which user reviewed which books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lxdkpTE_mbk"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4H3c-AE_mbm"
   },
   "source": [
    "### 2. Generating the reviews\n",
    "In this context, transactions are the reviews. You need to compile a list of lists, where each inner list contains reviews that are related, similar to how shopping lists are grouped in the example: `[['eggs','milk','bread'], ['bacon', 'bread'], [...], [...]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAj1AfOT_mbn"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3DoSE46_mbo"
   },
   "source": [
    "### 3. Calculate the Support Confidence\n",
    "This requires some puzzling, but looking at the source code will give you a clear idea. You can reuse the subroutines in the source code and pass along the list containing the reviews belonging together. Play around with the _minimum support_ parameter. Too strict will result in fewer associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5FwXRA__mbp"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GszZ0PPJ_mbq"
   },
   "source": [
    "### 4. Save the results\n",
    "Create a dataframe for the results of step 3. In order to make it work with the current app please make sure the columns are `source;target;support;confidence`. Save the recommendations as `recommendations-seeded-associations.csv` and replace the file in the app directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h856hpu-_mbr"
   },
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
